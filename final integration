#Code for Integration of HSV Colour Line Following & Hybrid Symbol Detection
import cv2
import numpy as np
import time
import threading
import queue
import RPi.GPIO as GPIO
from picamera2 import Picamera2
from ultralytics import YOLO
import os

# --- GPIO Setup ---
IN1, IN2, IN3, IN4 = 17, 18, 22, 23
ENA, ENB = 24, 25

GPIO.setmode(GPIO.BCM)
GPIO.setup([IN1, IN2, IN3, IN4, ENA, ENB], GPIO.OUT)

pwm_left = GPIO.PWM(ENA, 1000)
pwm_right = GPIO.PWM(ENB, 1000)
pwm_left.start(50)
pwm_right.start(50)

# --- Global Variables ---
frame_queue = queue.Queue(maxsize=1)  # Only keep the latest frame
control_queue = queue.Queue(maxsize=1)  # For passing control commands
display_queue = queue.Queue(maxsize=1)  # For displaying frames
running = True
direction = "Stopped"
detected_symbol = "None"
symbol_candidate_frame = None
symbol_triggered = False

# --- Control Functions ---
def set_speed(left, right):
    pwm_left.ChangeDutyCycle(left)
    pwm_right.ChangeDutyCycle(right)

def move_forward(): set_speed(60, 60); GPIO.output(IN1, 1); GPIO.output(IN2, 0); GPIO.output(IN3, 1); GPIO.output(IN4, 0)
def move_left():    set_speed(60, 70); GPIO.output(IN1, 1); GPIO.output(IN2, 0); GPIO.output(IN3, 0); GPIO.output(IN4, 1)
def move_right():   set_speed(70, 60); GPIO.output(IN1, 0); GPIO.output(IN2, 1); GPIO.output(IN3, 1); GPIO.output(IN4, 0)
def reverse():      set_speed(50, 50); GPIO.output(IN1, 0); GPIO.output(IN2, 1); GPIO.output(IN3, 0); GPIO.output(IN4, 1)
def stop():         set_speed(0, 0); GPIO.output(IN1, 0); GPIO.output(IN2, 0); GPIO.output(IN3, 0); GPIO.output(IN4, 0)


# --- Initialize Camera ---
picam2 = Picamera2()
picam2.preview_configuration.main.size = (320, 240)
picam2.preview_configuration.main.format = "RGB888"
picam2.configure("preview")
picam2.start()
time.sleep(2)  # Short warmup time

#Lock AWB settings
awb_gains = picam2.capture_metadata()['ColourGains']
picam2.set_controls({"AwbMode": 0, "ColourGains": awb_gains})

# --- Initialize YOLO Model (with smaller model) ---
# Use a smaller YOLO model like yolov8n or a custom-trained tiny model
model = YOLO('/home/user/yolov8/best.pt')  # Consider using a smaller model

# --- Camera Thread ---
def camera_thread():
    global running
    while running:
        frame = picam2.capture_array()
        # Replace old frame with new one
        if frame_queue.full():
            frame_queue.get()
        frame_queue.put(frame)
        time.sleep(0.01)  # Small delay to prevent CPU hogging

# --- Line Following Thread ---
def line_following_thread():
    global running, direction
    last_cx = 160  # start centered
    missed_detections = 0
    MAX_MISSES = 3
    target_colors = ['Red', 'Green']

    # Debug counter to print values periodically
    debug_counter = 0

    def get_color_name(hue):
        # Adjusted thresholds for better detection
         if 13 <= hue <= 17:      # Blue (from your hue: 11-12)
            return "Blue"
         elif 90 <= hue <= 100:    # Yellow (from your hue: 93-96)
            return "Yellow"
         elif 35 <= hue <= 90:    # Green (already working well)
            return "Green"
         elif 115<= hue <= 125:  # Red (from your hue: 120-122)
            return "Red"
         return None

    while running:
        if symbol_triggered:
            stop()
            time.sleep(0.1)
            continue
        
        if frame_queue.empty():
            time.sleep(0.01)
            continue

        # Get frame and convert to BGR (OpenCV standard)
        frame = frame_queue.get().copy()
        # Convert RGB to BGR (Picamera2 captures in RGB, OpenCV expects BGR)
        frame_bgr = cv2.cvtColor(frame, cv2.COLOR_RGB2BGR)
        
        height, width = frame_bgr.shape[:2]
        roi = frame_bgr[int(height * 3 / 4):, :]
        
        # Convert BGR to HSV
        hsv_roi = cv2.cvtColor(roi, cv2.COLOR_BGR2HSV)
        
        # === Detect Colored Line ===
        # Wider saturation range for better color detection
        mask_color = cv2.inRange(hsv_roi, np.array([0, 40, 40]), np.array([180, 255, 255]))
        
        # Apply morphology to clean up the mask
        kernel = np.ones((5,5), np.uint8)
        mask_color = cv2.morphologyEx(mask_color, cv2.MORPH_OPEN, kernel)
        
        contours, _ = cv2.findContours(mask_color, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
        contours = [c for c in contours if cv2.contourArea(c) > 500]

        color_detected = False
        if contours:
            largest = max(contours, key=cv2.contourArea)
            M = cv2.moments(largest)
            if M["m00"] != 0:
                cx = int(M["m10"] / M["m00"])
                last_cx = cx
                missed_detections = 0

                # Create a blank mask and draw the contour on it
                temp_mask = np.zeros_like(mask_color)
                cv2.drawContours(temp_mask, [largest], -1, 255, -1)
                
                # Calculate mean hue for the contour area
                mean_hsv = cv2.mean(hsv_roi, mask=temp_mask)
                hue = mean_hsv[0]
                
                # Print debug info occasionally
                debug_counter += 1
                if debug_counter % 10 == 0:  # Print every 10th frame
                    print(f"Hue: {hue:.1f}, S: {mean_hsv[1]:.1f}, V: {mean_hsv[2]:.1f}")
                
                color_name = get_color_name(hue)

                if color_name in target_colors:
                    color_detected = True
                    if cx < 140:
                        control_queue.put("left")
                        direction = f"{color_name}: Left"
                    elif cx > 180:
                        control_queue.put("right")
                        direction = f"{color_name}: Right"
                    else:
                        control_queue.put("forward")
                        direction = f"{color_name}: Straight"
                elif color_name:
                    direction = f"Ignoring {color_name}"
                    color_detected = True

        # === Black line fallback ===
        if not color_detected:
            lower_black = np.array([0, 0, 0])
            upper_black = np.array([180, 255, 50])
            mask_black = cv2.inRange(hsv_roi, lower_black, upper_black)
            contours_bw, _ = cv2.findContours(mask_black, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
            contours_bw = [c for c in contours_bw if cv2.contourArea(c) > 500]

            if contours_bw:
                largest = max(contours_bw, key=cv2.contourArea)
                M = cv2.moments(largest)
                if M["m00"] != 0:
                    cx = int(M["m10"] / M["m00"])
                    last_cx = cx
                    missed_detections = 0

                    if cx < 140:
                        control_queue.put("left")
                        direction = "Black Line: Left"
                    elif cx > 180:
                        control_queue.put("right")
                        direction = "Black Line: Right"
                    else:
                        control_queue.put("forward")
                        direction = "Black Line: Straight"
            else:
                missed_detections += 1
                if missed_detections > MAX_MISSES:
                    control_queue.put("reverse")
                    direction = "Lost Line - Reverse"

        # Create visualization frame
        display_frame = frame.copy()  # Use original RGB frame for display
        
        # Draw contours on visualization
        if 'largest' in locals():
            cv2.drawContours(display_frame[int(height * 3 / 4):, :], [largest], -1, (0, 255, 0), 2)
        
        cv2.putText(display_frame, f"Direction: {direction}", (10, 20), 
                    cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 255), 1)
        cv2.putText(display_frame, f"Symbol: {detected_symbol}", (10, 40), 
                    cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 255), 1)
                    
        # Add color name display when detected
        if 'color_name' in locals() and color_name:
            cv2.putText(display_frame, f"Color: {color_name}", (10, 60),
                        cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 255), 1)

        if display_queue.full():
            display_queue.get()
        display_queue.put(display_frame)

        time.sleep(0.02)
        
# --- Symbol Detection Thread ---
TEMPLATE_DIR = "/home/pi/templates/"  # Set this to your actual template path

template_files = {
    "Right Arrow": ("right arrow.png", 0.65),
    "Left Arrow": ("left arrow.png", 0.65),
    "Up Arrow": ("up arrow.png", 0.65),
    "Down Arrow": ("down arrow.png", 0.65),
    "Stop Sign": ("stop sign.png", 0.6),
    "Distancing Sign": ("distance measurement.png", 0.4),
    "Traffic Light Stop": ("traffic light stop.png", 0.5),
    "Face Recognition": ("face recognition.png", 0.35),
    "Pentagon": ("pentagon.png", 0.65),
    "Partial circle": ("partial circle.png", 0.7),
    "Rectangle": ("rectangle.png", 0.65),
    "Hexagon": ("hexagon.png", 0.65),
    "Triangle": ("triangle.png", 0.65),
    "Circle": ("circle.png", 0.65)
}

templates = {}
for symbol, (filename, threshold) in template_files.items():
    path = os.path.join(TEMPLATE_DIR, filename)
    template = cv2.imread(path, cv2.IMREAD_GRAYSCALE)
    if template is None:
        print(f"⚠️ Warning: Could not load {filename}. Check path.")
    else:
        templates[symbol] = (template, threshold)
        
def multi_scale_template_match(image, template, threshold):
    detected = False
    max_val_global = 0
    loc_global = None
    size_global = None

    img_h, img_w = image.shape  # Input image dimensions

    for scale in np.linspace(0.5, 2.0, 10):  # Reasonable scale range for performance
        width = max(1, int(template.shape[1] * scale))  
        height = max(1, int(template.shape[0] * scale)) 

        # Skip scales that make the template larger than the image
        if width > img_w or height > img_h:
            continue

        resized = cv2.resize(template, (width, height))

        result = cv2.matchTemplate(image, resized, cv2.TM_CCOEFF_NORMED)
        _, max_val, _, max_loc = cv2.minMaxLoc(result)

        if max_val > max_val_global:
            max_val_global = max_val
            loc_global = max_loc
            size_global = (width, height)

    if max_val_global > threshold:
        detected = True

    return detected, max_val_global, loc_global, size_global

def template_matching_thread():
    global running, symbol_triggered, symbol_candidate_frame

    while running:
        if frame_queue.empty():
            time.sleep(0.05)
            continue

        frame = frame_queue.get().copy()
        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)
        gray = cv2.GaussianBlur(gray, (5, 5), 0)

        for symbol_name, (template, threshold) in templates.items():
            detected, score, loc, size = multi_scale_template_match(gray, template, threshold)
            if detected:
                print(f"Template match found for {symbol_name} (score: {score:.2f})")
                symbol_triggered = True
                symbol_candidate_frame = frame
                control_queue.put("stop")  # Pause robot on symbol detection
                time.sleep(0.5)  # Small delay before YOLO takes over
                break

        time.sleep(0.1)


def yolo_thread():
    global running, detected_symbol, symbol_triggered, symbol_candidate_frame

    while running:
        if not symbol_triggered or symbol_candidate_frame is None:
            time.sleep(0.05)
            continue

        frame = symbol_candidate_frame.copy()
        results = model(frame)[0]

        detected_symbol = "None"
        for r in results.boxes.data.tolist():
            _, _, _, _, conf, cls = r
            if conf > 0.5:
                detected_symbol = model.names[int(cls)]
                print(f"YOLO detected: {detected_symbol} (conf: {conf:.2f})")
                break

        symbol_triggered = False
        time.sleep(0.1)


# --- Motor Control Thread ---
def motor_control_thread():
    global running
    last_command = "stop"
    reverse_start_time = None
    REVERSE_DURATION = 0.05  # Reverse for 0.05 seconds

    while running:
        # Check if currently reversing
        if reverse_start_time is not None:
            if time.time() - reverse_start_time < REVERSE_DURATION:
                reverse()  # Continue reversing
                time.sleep(0.02)  # Maintain ~50Hz loop rate
                continue
            else:
                stop()  # Stop after reverse duration
                last_command = "stop"
                reverse_start_time = None  # Reset reverse state

        # Process new commands
        try:
            command = control_queue.get(timeout=0.1)
            last_command = command
        except queue.Empty:
            command = last_command

        # Execute command
        if command == "forward":
            move_forward()
        elif command == "left":
            move_left()
        elif command == "right":
            move_right()
        elif command == "reverse":
            reverse()
            reverse_start_time = time.time()  # Start reverse timer
        elif command == "stop":
            stop()

        time.sleep(0.02)  # Run at ~50Hz
        
# --- Display Thread ---
def display_thread():
    global running
    
    while running:
        if not display_queue.empty():
            frame = display_queue.get()
            cv2.imshow("Robot Vision", frame)
            
        if cv2.waitKey(1) & 0xFF == ord('q'):
            running = False
            break
            
        time.sleep(0.03)  # ~30 FPS display

# --- Main Function ---
def main():
    global running
    threads = []
    
    # Start threads
    threads.append(threading.Thread(target=camera_thread))
    threads.append(threading.Thread(target=line_following_thread))
    threads.append(threading.Thread(target=template_matching_thread))
    threads.append(threading.Thread(target=yolo_thread))
    threads.append(threading.Thread(target=motor_control_thread))
    threads.append(threading.Thread(target=display_thread))
    
    for t in threads:
        t.daemon = True
        t.start()
    
    try:
        # Main thread can do other tasks or just wait
        while running:
            time.sleep(0.1)
    except KeyboardInterrupt:
        print("Shutting down...")
    finally:
        running = False
        
        # Wait for threads to finish
        for t in threads:
            t.join(timeout=1.0)
            
        # Cleanup
        stop()
        pwm_left.stop()
        pwm_right.stop()
        GPIO.cleanup()
        cv2.destroyAllWindows()
        
if __name__ == "__main__":
    main()
